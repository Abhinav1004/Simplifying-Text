{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install libraries"
      ],
      "metadata": {
        "id": "Pf3HJ8MEHmcW"
      },
      "id": "Pf3HJ8MEHmcW"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYyaDb3VAiVv",
        "outputId": "ac0f0172-b2bc-4801-b2d9-b8c251f79c2a"
      },
      "id": "DYyaDb3VAiVv",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install textstat\n",
        "# !pip install pytorch-lightning\n",
        "# !pip install keybert\n",
        "# !git clone https://github.com/feralvam/easse.git\n",
        "# !pip install -e ./easse"
      ],
      "metadata": {
        "id": "XPfFTIrr81O-"
      },
      "id": "XPfFTIrr81O-",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets_base_dir = \"/content/drive/MyDrive/NLP-Sem-3 Project\""
      ],
      "metadata": {
        "id": "jNZ3te4vAwe5"
      },
      "id": "jNZ3te4vAwe5",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code"
      ],
      "metadata": {
        "id": "wm0bRYhEHqd7"
      },
      "id": "wm0bRYhEHqd7"
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZggedSaIviV",
        "outputId": "f699fdf1-752a-46f9-fb76-e2c622875377"
      },
      "id": "VZggedSaIviV",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "175b8585-4037-42c7-a96c-a4892f30e8fa",
      "metadata": {
        "id": "175b8585-4037-42c7-a96c-a4892f30e8fa"
      },
      "outputs": [],
      "source": [
        "# from utils.utils\n",
        "# Import relevant libraries\n",
        "import time\n",
        "import json\n",
        "from pathlib import Path\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "def create_experiment_dir(repo_dir, model_config):\n",
        "    \"\"\"\n",
        "    Create a unique experiment directory based on the current timestamp and model configuration.\n",
        "\n",
        "    Args:\n",
        "        repo_dir: The repository directory location\n",
        "        model_config: The configuration dictionary to include in the directory name\n",
        "\n",
        "    Returns:\n",
        "        Path: The created experiment directory path\n",
        "    \"\"\"\n",
        "    # Make sure repo_dir is a Path object\n",
        "    if not isinstance(repo_dir, Path):\n",
        "        repo_dir = Path(repo_dir)\n",
        "\n",
        "    # Find the next folder number based on existing directories\n",
        "    existing_dirs = [d for d in repo_dir.iterdir() if d.is_dir()]\n",
        "    next_number = 1 + max(\n",
        "        (int(d.name.split('_')[0]) for d in existing_dirs if d.name.split('_')[0].isdigit()),\n",
        "        default=0\n",
        "    )\n",
        "\n",
        "    # Construct a directory name with model configuration values\n",
        "    dir_name = (\n",
        "        f\"{next_number}_\"\n",
        "        f\"{model_config['model_name']}_\"\n",
        "        f\"{model_config['dataset']}_\"\n",
        "        f\"epochs-{model_config['num_train_epochs']}_\"\n",
        "        f\"batch-{model_config['train_batch_size']}_\"\n",
        "        f\"val_batch-{model_config['valid_batch_size']}_\"\n",
        "        f\"lambda-{model_config['lambda_']}_\"\n",
        "        f\"prompt-{model_config['prompting_strategy']}_\"\n",
        "        f\"div-{model_config['div_score']}_\"\n",
        "        f\"keywords-{model_config['top_keywords']}_\"\n",
        "        f\"test_sample-{model_config['test_sample_size']}\"\n",
        "    )\n",
        "    print(dir_name)\n",
        "    path = repo_dir / dir_name\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "    return path\n",
        "\n",
        "def log_parameters(filepath, parameters):\n",
        "    \"\"\"\n",
        "    Log parameters to a JSON file.\n",
        "\n",
        "    Args:\n",
        "        filepath: Path to the JSON file\n",
        "        parameters: Parameters to log\n",
        "    \"\"\"\n",
        "    with filepath.open('w') as f:\n",
        "        json.dump({k: str(v) for k, v in parameters.items()}, f, indent=4)\n",
        "\n",
        "\n",
        "def save_log(output_dir, model_name, epoch, loss=None, sari=None, data_type='train'):\n",
        "    \"\"\"\n",
        "    Save log for training or validation data.\n",
        "\n",
        "    Args:\n",
        "        output_dir: output directory\n",
        "        model_name: use model name to save\n",
        "        epoch (int): Current epoch.\n",
        "        loss (float): Loss value (optional).\n",
        "        sari (float): SARI score (optional).\n",
        "        data_type: Data type train or validation\n",
        "    \"\"\"\n",
        "    if data_type == 'train':\n",
        "        with open('{}/{}_training_log.csv'.format(output_dir, model_name.replace(\"/\", \"-\")), 'a') as f:\n",
        "            log_line = f\"{epoch},{loss if loss is not None else ''}\\n\"\n",
        "            f.write(log_line)\n",
        "    elif data_type == 'validation':\n",
        "        with open('{}/{}_validation_log.csv'.format(output_dir, model_name.replace(\"/\", \"-\")), 'a') as f:\n",
        "            log_line = f\"{epoch},{loss if loss is not None else ''},{sari if sari is not None else ''}\\n\"\n",
        "            f.write(log_line)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a3887712-7e66-4013-99ab-7ccdbf0a6619",
      "metadata": {
        "id": "a3887712-7e66-4013-99ab-7ccdbf0a6619"
      },
      "outputs": [],
      "source": [
        "# from preprocessing\n",
        "\n",
        "# Import required libraries\n",
        "from pathlib import Path\n",
        "import hashlib\n",
        "\n",
        "\n",
        "def yield_lines(filepath):\n",
        "    \"\"\"\n",
        "    Generator function to yield lines from a file.\n",
        "\n",
        "    Args:\n",
        "        filepath (str or Path): Path to the file.\n",
        "\n",
        "    Yields:\n",
        "        str: Each line from the file, stripped of trailing whitespace.\n",
        "    \"\"\"\n",
        "    filepath = Path(filepath)\n",
        "    with filepath.open('r') as f:\n",
        "        for line in f:\n",
        "            yield line.rstrip()\n",
        "\n",
        "\n",
        "def read_lines(filepath):\n",
        "    \"\"\"\n",
        "    Reads all lines from a file and returns them as a list.\n",
        "\n",
        "    Args:\n",
        "        filepath (str or Path): Path to the file.\n",
        "\n",
        "    Returns:\n",
        "        list: List of lines from the file, each stripped of trailing whitespace.\n",
        "    \"\"\"\n",
        "    return [line.rstrip() for line in yield_lines(filepath)]\n",
        "\n",
        "\n",
        "def get_data_filepath(data_set_dir, dataset, phase, data_type, i=None):\n",
        "    \"\"\"\n",
        "    Constructs the file path for a dataset file based on provided parameters.\n",
        "\n",
        "    Args:\n",
        "        data_set_dir (str or Path): Directory containing datasets.\n",
        "        dataset (str): Name of the dataset.\n",
        "        phase (str): Phase of the data (e.g., 'train' or 'valid').\n",
        "        data_type (str): Type of data (e.g., 'complex' or 'simple').\n",
        "        i (int, optional): Optional index to append as a suffix to the filename.\n",
        "\n",
        "    Returns:\n",
        "        Path: Constructed file path as a Path object.\n",
        "    \"\"\"\n",
        "    suffix = f'.{i}' if i is not None else ''\n",
        "    data_filename = f'{dataset}.{phase}.{data_type}{suffix}'\n",
        "    return Path(data_set_dir) / dataset / data_filename\n",
        "\n",
        "\n",
        "def generate_hash(data):\n",
        "    h = hashlib.new('md5')\n",
        "    h.update(str(data).encode())\n",
        "    return h.hexdigest()\n",
        "\n",
        "\n",
        "def count_line(filepath):\n",
        "    filepath = Path(filepath)\n",
        "    line_count = 0\n",
        "    with filepath.open(\"r\") as f:\n",
        "        for line in f:\n",
        "            line_count += 1\n",
        "    return line_count\n",
        "\n",
        "\n",
        "def write_lines(lines, filepath):\n",
        "    filepath = Path(filepath)\n",
        "    filepath.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with filepath.open(\"w\") as fout:\n",
        "        for line in lines:\n",
        "            fout.write(line + '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e62c1d59-8d69-4922-a72a-d1f86a46963b",
      "metadata": {
        "id": "e62c1d59-8d69-4922-a72a-d1f86a46963b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from util.train_valid_data_generation\n",
        "\n",
        "# Import libraries\n",
        "from torch.utils.data import Dataset\n",
        "# from util.processing.preprocessor import (\n",
        "#     yield_lines, read_lines, get_data_filepath\n",
        "# )\n",
        "\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, data_set_dir, dataset, tokenizer, max_len=256, sample_size=1):\n",
        "        \"\"\"\n",
        "        Initializes the training dataset.\n",
        "\n",
        "        Args:\n",
        "            data_set_dir: Path to data\n",
        "            dataset: Name of the dataset.\n",
        "            tokenizer: Tokenizer object to tokenize the data.\n",
        "            max_len (int): Maximum length of the tokenized sequences.\n",
        "            sample_size (float): Fraction of the dataset to sample.\n",
        "        \"\"\"\n",
        "        self.sample_size = sample_size\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        print(\"Initializing TrainDataset...\")\n",
        "        self.source_filepath = get_data_filepath(data_set_dir, dataset, 'train', 'complex')\n",
        "        self.target_filepath = get_data_filepath(data_set_dir, dataset, 'train', 'simple')\n",
        "        print(\"Dataset paths initialized.\")\n",
        "\n",
        "        self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        \"\"\"Loads the source and target data.\"\"\"\n",
        "        self.inputs = read_lines(self.source_filepath)\n",
        "        self.targets = read_lines(self.target_filepath)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Returns the length of the dataset based on the sample size.\"\"\"\n",
        "        return int(len(self.inputs) * self.sample_size)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Fetches a single item from the dataset.\"\"\"\n",
        "        source = self.inputs[index]\n",
        "        target = self.targets[index]\n",
        "\n",
        "        tokenized_inputs = self.tokenizer(\n",
        "            [source],\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        tokenized_targets = self.tokenizer(\n",
        "            [target],\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        source_ids = tokenized_inputs[\"input_ids\"].squeeze()\n",
        "        target_ids = tokenized_targets[\"input_ids\"].squeeze()\n",
        "        src_mask = tokenized_inputs[\"attention_mask\"].squeeze()\n",
        "        target_mask = tokenized_targets[\"attention_mask\"].squeeze()\n",
        "\n",
        "        return {\n",
        "            \"source_ids\": source_ids,\n",
        "            \"source_mask\": src_mask,\n",
        "            \"target_ids\": target_ids,\n",
        "            \"target_mask\": target_mask,\n",
        "            \"sources\": source,\n",
        "            \"targets\": [target],\n",
        "            \"source\": source,\n",
        "            \"target\": target\n",
        "        }\n",
        "\n",
        "\n",
        "class ValDataset(Dataset):\n",
        "    def __init__(self, data_set_dir, dataset, tokenizer, max_len=256, sample_size=1):\n",
        "        \"\"\"\n",
        "        Initializes the validation dataset.\n",
        "\n",
        "        Args:\n",
        "            data_set_dir: Path to data\n",
        "            dataset: Name or path of the dataset.\n",
        "            tokenizer: Tokenizer object to tokenize the data.\n",
        "            max_len (int): Maximum length of the tokenized sequences.\n",
        "            sample_size (float): Fraction of the dataset to sample.\n",
        "        \"\"\"\n",
        "        self.sample_size = sample_size\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        print(\"Initializing ValDataset...\")\n",
        "        self.source_filepath = get_data_filepath(data_set_dir, dataset, 'valid', 'complex')\n",
        "        self.target_filepaths = get_data_filepath(data_set_dir, dataset, 'valid', 'simple')\n",
        "        print(\"Dataset paths initialized.\")\n",
        "\n",
        "        self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        \"\"\"Loads the source and target data.\"\"\"\n",
        "        self.inputs = [line for line in yield_lines(self.source_filepath)]\n",
        "        self.targets = [line for line in yield_lines(self.target_filepaths)]\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Returns the length of the dataset based on the sample size.\"\"\"\n",
        "        return int(len(self.inputs) * self.sample_size)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Fetches a single item from the dataset.\"\"\"\n",
        "        return {\n",
        "            \"source\": self.inputs[index],\n",
        "            \"targets\": self.targets[index]\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3fccdf2a-45b3-48c2-adbe-00f84ee7ae05",
      "metadata": {
        "id": "3fccdf2a-45b3-48c2-adbe-00f84ee7ae05"
      },
      "outputs": [],
      "source": [
        "# from evaluate_model.evaluation metrics\n",
        "\n",
        "# Import necessary libraries\n",
        "from nltk.tokenize import word_tokenize\n",
        "from pathlib import Path\n",
        "import textstat\n",
        "# from util.processing.preprocessor import get_data_filepath\n",
        "from easse.sari import corpus_sari as easse_corpus_sari\n",
        "from easse.fkgl import corpus_fkgl as easse_corpus_fkgl\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def load_dataset_validation(dataset_dir, dataset_name, phase='test', percentage=1.0):\n",
        "    \"\"\"\n",
        "    Load the dataset for evaluation with an optional parameter to specify the percentage of data to be used.\n",
        "\n",
        "    Args:\n",
        "        dataset_dir (str or Path): Path to the dataset directory.\n",
        "        dataset_name (str): Name of the dataset (e.g., 'dwiki' or 'wiki_doc').\n",
        "        phase (str): Dataset phase to load ('train', 'valid', 'test').\n",
        "        percentage (float): Percentage of data to be used (value between 0.0 and 1.0).\n",
        "\n",
        "    Returns:\n",
        "        tuple: (list of complex sentences, list of simple sentences)\n",
        "    \"\"\"\n",
        "    complex_filepath = get_data_filepath(dataset_dir, dataset_name, phase, 'complex')\n",
        "    simple_filepath = get_data_filepath(dataset_dir, dataset_name, phase, 'simple')\n",
        "\n",
        "    # Read lines from files\n",
        "    complex_sents = Path(complex_filepath).read_text().splitlines()\n",
        "    simple_sents = Path(simple_filepath).read_text().splitlines()\n",
        "\n",
        "    # Use the specified percentage of the data\n",
        "    data_size = len(complex_sents)\n",
        "    selected_size = int(data_size * percentage)\n",
        "\n",
        "    # Randomly select the data subset\n",
        "    indices = list(range(data_size))\n",
        "    random.shuffle(indices)\n",
        "    selected_indices = indices[:selected_size]\n",
        "\n",
        "    complex_sents = [complex_sents[i] for i in selected_indices]\n",
        "    simple_sents = [simple_sents[i] for i in selected_indices]\n",
        "\n",
        "    return complex_sents, simple_sents\n",
        "\n",
        "\n",
        "\n",
        "class BartModelEvaluator:\n",
        "    \"\"\"\n",
        "    A class for evaluating a BART-based summarization model using SARI, D-SARI, and FKGL metrics.\n",
        "\n",
        "    Args:\n",
        "        model_config : Configuration dictionary containing the device to run the model on (\"cuda\", \"cpu\", or \"cpu\").\n",
        "        model (BartForConditionalGeneration): Pre-trained BART model to evaluate.\n",
        "        tokenizer (BartTokenizer): Tokenizer for the BART model.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_config, model, tokenizer):\n",
        "        self.model = model.to(model_config['device'])\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = model_config['device']\n",
        "        self.max_seq_length = model_config['max_seq_length']\n",
        "        self.output_location = model_config['output_dir']\n",
        "\n",
        "    def generate_summary(self, sentence, max_length=256):\n",
        "        \"\"\"\n",
        "        Generate a summary for a given input sentence using the BART model.\n",
        "\n",
        "        Args:\n",
        "            sentence (str): Input sentence to be summarized.\n",
        "            max_length (int): Maximum length of the generated summary.\n",
        "\n",
        "        Returns:\n",
        "            str: Generated summary.\n",
        "        \"\"\"\n",
        "        inputs = self.tokenizer(\n",
        "            sentence,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=self.max_seq_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\"\n",
        "        ).to(self.device)\n",
        "\n",
        "        input_ids = inputs[\"input_ids\"]\n",
        "        attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "        summary_ids = self.model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=max_length,\n",
        "            num_beams=5,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "        return self.tokenizer.decode(summary_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_sari_and_d_sari(source_sent, predicted_sent, references):\n",
        "        \"\"\"\n",
        "        Calculate SARI and D-SARI scores for text simplification.\n",
        "\n",
        "        Args:\n",
        "            source_sent (str): Source sentence.\n",
        "            predicted_sent (str): Predicted simplified sentence.\n",
        "            references (list): List of reference simplified sentences.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (SARI score, D-SARI score)\n",
        "        \"\"\"\n",
        "        source_tokens = set(word_tokenize(source_sent))\n",
        "        predicted_tokens = set(word_tokenize(predicted_sent))\n",
        "        reference_tokens = [set(word_tokenize(ref)) for ref in references]\n",
        "\n",
        "        # Calculate addition, deletion, and keep scores\n",
        "        add_scores = [\n",
        "            len(predicted_tokens - ref) / max(1, len(predicted_tokens))\n",
        "            for ref in reference_tokens\n",
        "        ]\n",
        "        keep_scores = [\n",
        "            len(predicted_tokens & ref) / max(1, len(ref))\n",
        "            for ref in reference_tokens\n",
        "        ]\n",
        "        delete_score = len(source_tokens - predicted_tokens) / max(1, len(source_tokens))\n",
        "\n",
        "        sari = (sum(add_scores) + sum(keep_scores) + delete_score) / (len(add_scores) + len(keep_scores) + 1)\n",
        "        d_sari = delete_score  # D-SARI focuses specifically on the deletion component\n",
        "\n",
        "        return sari, d_sari\n",
        "\n",
        "    def calculate_fkgl(self, text):\n",
        "        \"\"\"\n",
        "        Calculate the Flesch-Kincaid Grade Level (FKGL) score.\n",
        "\n",
        "        Args:\n",
        "            text (str): Input text.\n",
        "\n",
        "        Returns:\n",
        "            float: FKGL score.\n",
        "        \"\"\"\n",
        "        return textstat.flesch_kincaid_grade(text)\n",
        "\n",
        "    import pandas as pd\n",
        "\n",
        "    def evaluate(self, source_sentences, reference_sentences):\n",
        "        \"\"\"\n",
        "        Evaluate a set of source and reference sentences using SARI, D-SARI, and FKGL metrics.\n",
        "\n",
        "        Args:\n",
        "            source_sentences (list): List of source sentences to be simplified.\n",
        "            reference_sentences (list): List of corresponding reference sentences.\n",
        "\n",
        "        Returns:\n",
        "            dict: Dictionary containing average SARI, D-SARI, and FKGL scores.\n",
        "        \"\"\"\n",
        "        total_sari, total_d_sari, total_fkgl = 0, 0, 0\n",
        "        predictions = []\n",
        "        metrics = []\n",
        "\n",
        "        for i, source_sent in enumerate(tqdm(source_sentences, desc=\"Evaluating sentences\")):\n",
        "            try:\n",
        "                predicted_sent = self.generate_summary(source_sent)\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating summary for sample {i}: {e}\")\n",
        "                predicted_sent = \"\"  # Fallback to an empty prediction\n",
        "\n",
        "            predictions.append(predicted_sent)\n",
        "            references = [reference_sentences[i]]  # Assuming one reference per source\n",
        "\n",
        "            # Calculate SARI and D-SARI scores\n",
        "            sari, d_sari = self.calculate_sari_and_d_sari(source_sent, predicted_sent, references)\n",
        "            total_sari += sari\n",
        "            total_d_sari += d_sari\n",
        "\n",
        "            # Calculate FKGL score\n",
        "            fkgl = self.calculate_fkgl(predicted_sent)\n",
        "            total_fkgl += fkgl\n",
        "\n",
        "            # Calculate EASSE SARI and FKGL for this sample\n",
        "            try:\n",
        "                easse_sari = easse_corpus_sari(orig_sents=[source_sent], sys_sents=[predicted_sent],\n",
        "                                               refs_sents=[references])\n",
        "                easse_fkgl = easse_corpus_fkgl([predicted_sent])\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculating EASSE metrics for sample {i}: {e}\")\n",
        "                easse_sari = 0\n",
        "                easse_fkgl = 0\n",
        "\n",
        "            # # Print metrics for the sample\n",
        "            # print(f\"Sample {i + 1}/{len(source_sentences)}\")\n",
        "            # print(f\"Source: {source_sent}\")\n",
        "            # print(f\"Predicted: {predicted_sent}\")\n",
        "            # print(f\"Reference: {references[0]}\")\n",
        "            # print(f\"SARI: {sari:.2f}, D-SARI: {d_sari:.2f}, FKGL: {fkgl:.2f}\")\n",
        "            # print(f\"EASSE SARI: {easse_sari:.2f}, EASSE FKGL: {easse_fkgl:.2f}\\n\")\n",
        "\n",
        "            # Store metrics in a dictionary for each sample\n",
        "            metrics.append({\n",
        "                'Sample': i + 1,\n",
        "                'Source': source_sent,\n",
        "                'Predicted': predicted_sent,\n",
        "                'Reference': references[0],\n",
        "                'SARI': sari,\n",
        "                'D-SARI': d_sari,\n",
        "                'FKGL': fkgl,\n",
        "                'EASSE SARI': easse_sari,\n",
        "                'EASSE FKGL': easse_fkgl\n",
        "            })\n",
        "\n",
        "        # Calculate average scores\n",
        "        avg_sari = total_sari / len(source_sentences)\n",
        "        avg_d_sari = total_d_sari / len(source_sentences)\n",
        "        avg_fkgl = total_fkgl / len(source_sentences)\n",
        "\n",
        "        # Calculate EASSE SARI and FKGL scores for all predictions\n",
        "        try:\n",
        "            easse_sari = easse_corpus_sari(orig_sents=source_sentences, sys_sents=predictions,\n",
        "                                           refs_sents=[reference_sentences])\n",
        "            easse_fkgl = easse_corpus_fkgl(predictions)\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating EASSE metrics for all predictions: {e}\")\n",
        "            easse_sari = 0\n",
        "            easse_fkgl = 0\n",
        "\n",
        "        print(f\"Average SARI: {avg_sari:.2f}\")\n",
        "        print(f\"Average D-SARI: {avg_d_sari:.2f}\")\n",
        "        print(f\"Average FKGL: {avg_fkgl:.2f}\")\n",
        "        print(f\"EASSE SARI: {easse_sari:.2f}\")\n",
        "        print(f\"EASSE FKGL: {easse_fkgl:.2f}\")\n",
        "\n",
        "        # Save metrics to a CSV file using pandas\n",
        "        df = pd.DataFrame(metrics)\n",
        "        df.to_csv('{}/evaluation_metrics_baseline.csv'.format(self.output_location), index=False)\n",
        "\n",
        "        return {\n",
        "            \"SARI\": avg_sari,\n",
        "            \"D-SARI\": avg_d_sari,\n",
        "            \"FKGL\": avg_fkgl,\n",
        "            \"EASSE SARI\": easse_sari,\n",
        "            \"EASSE FKGL\": easse_fkgl\n",
        "        }, df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "785b1a69-9ea8-4de3-87f4-5569107d8e37",
      "metadata": {
        "id": "785b1a69-9ea8-4de3-87f4-5569107d8e37"
      },
      "outputs": [],
      "source": [
        "# baseline_models.baseline_model\n",
        "\n",
        "# Import necessary libraries\n",
        "from torch.utils.data import DataLoader\n",
        "# from util.train_valid_data_generation import TrainDataset, ValDataset\n",
        "import pytorch_lightning as pl\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    AutoModelForSeq2SeqLM, AutoTokenizer,\n",
        "    get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
        ")\n",
        "from easse.sari import corpus_sari\n",
        "# from util.utils import save_log\n",
        "\n",
        "\n",
        "class Seq2SeqFineTunedModel(pl.LightningModule):\n",
        "    \"\"\"\n",
        "    A generic PyTorch Lightning module for fine-tuning a sequence-to-sequence model for summarization or text simplification.\n",
        "\n",
        "    Args:\n",
        "        training_parameters (dict): Dictionary of training parameters.\n",
        "        model_name (str): Pre-trained model to fine-tune (e.g., 't5-base', 'Yale-LILY/brio-cnndm-uncased').\n",
        "    \"\"\"\n",
        "    def __init__(self, training_parameters, model_name='t5-base'):\n",
        "        super(Seq2SeqFineTunedModel, self).__init__()\n",
        "\n",
        "        # Store hyperparameters and initialize model and tokenizer\n",
        "        self.save_hyperparameters()\n",
        "        self.training_parameters = training_parameters\n",
        "        self.device_name = training_parameters['device']\n",
        "\n",
        "        # Initialize parameters from the training dictionary\n",
        "        self.model_name = training_parameters['model_name']\n",
        "        self.train_batch_size = training_parameters['train_batch_size']\n",
        "        self.valid_batch_size = training_parameters['valid_batch_size']\n",
        "        self.learning_rate = training_parameters['learning_rate']\n",
        "        self.max_seq_length = training_parameters['max_seq_length']\n",
        "        self.adam_epsilon = training_parameters['adam_epsilon']\n",
        "        self.weight_decay = training_parameters['weight_decay']\n",
        "        self.warmup_steps = training_parameters['warmup_steps']\n",
        "        self.train_sample_size = training_parameters['train_sample_size']\n",
        "        self.valid_sample_size = training_parameters['valid_sample_size']\n",
        "        self.num_train_epochs = training_parameters['num_train_epochs']\n",
        "        self.gradient_accumulation_steps = training_parameters['gradient_accumulation_steps']\n",
        "        self.custom_loss = training_parameters.get('custom_loss', False)\n",
        "        self.scheduler_type = training_parameters.get('scheduler_type', 'linear')\n",
        "        with open('{}/{}_training_log.csv'.format(\n",
        "                self.training_parameters['output_dir'],\n",
        "                self.training_parameters['model_name'].replace(\"/\", \"-\")\n",
        "        ), 'w') as f: f.write('epoch,loss\\n')\n",
        "        with open('{}/{}_validation_log.csv'.format(\n",
        "                training_parameters['output_dir'],\n",
        "                self.training_parameters['model_name'].replace(\"/\", \"-\")\n",
        "        ), 'w') as f: f.write('epoch,loss,sari\\n')\n",
        "\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained(self.model_name).to(self.device_name)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "\n",
        "        # Data and output paths\n",
        "        self.dataset = self.training_parameters['dataset']\n",
        "        self.data_location = self.training_parameters['data_location']\n",
        "        self.model_store_path = training_parameters['output_dir'] / (model_name + '_fine_tuned')\n",
        "\n",
        "    def is_logger(self):\n",
        "        \"\"\"\n",
        "        Returns True if this is the first rank (for distributed training), False otherwise.\n",
        "        \"\"\"\n",
        "        return self.trainer.global_rank <= 0\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, decoder_input_ids=None,\n",
        "                decoder_attention_mask=None, labels=None):\n",
        "        \"\"\"\n",
        "        Defines the forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            input_ids (tensor): Input tensor containing tokenized input IDs.\n",
        "            attention_mask (tensor): Attention mask for the input.\n",
        "            decoder_input_ids (tensor): Decoder input IDs for sequence generation.\n",
        "            decoder_attention_mask (tensor): Attention mask for the decoder.\n",
        "            labels (tensor): Target labels for training.\n",
        "\n",
        "        Returns:\n",
        "            ModelOutput: Model's output, including loss if labels are provided.\n",
        "        \"\"\"\n",
        "        return self.model(input_ids=input_ids,\n",
        "                          attention_mask=attention_mask,\n",
        "                          decoder_input_ids=decoder_input_ids,\n",
        "                          decoder_attention_mask=decoder_attention_mask,\n",
        "                          labels=labels)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Performs a training step, computes loss, and logs the results.\n",
        "\n",
        "        Args:\n",
        "            batch (dict): Batch of training data.\n",
        "            batch_idx (int): Index of the current batch.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Loss value for the current batch.\n",
        "        \"\"\"\n",
        "        source = batch[\"source\"]\n",
        "        labels = batch['target_ids']\n",
        "\n",
        "        # Ignore padding tokens in loss calculation\n",
        "        labels[labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        outputs = self(input_ids=batch[\"source_ids\"],\n",
        "                       attention_mask=batch[\"source_mask\"],\n",
        "                       labels=labels,\n",
        "                       decoder_attention_mask=batch[\"target_mask\"])\n",
        "\n",
        "        loss = outputs.loss\n",
        "        self.log('train_loss', loss, on_step=True, prog_bar=True, logger=True)\n",
        "        save_log(\n",
        "            self.training_parameters['output_dir'],\n",
        "            self.training_parameters['model_name'],\n",
        "            self.current_epoch,\n",
        "            loss=loss.item(),\n",
        "            data_type='train'\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Performs a validation step, computes loss, and logs the results.\n",
        "\n",
        "        Args:\n",
        "            batch (dict): Batch of validation data.\n",
        "            batch_idx (int): Index of the current batch.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Loss value for the current batch.\n",
        "        \"\"\"\n",
        "        loss = self.sari_validation_step(batch)\n",
        "        self.log('val_loss', loss, batch_size=self.valid_batch_size)\n",
        "        return loss\n",
        "\n",
        "    def sari_validation_step(self, batch):\n",
        "        \"\"\"\n",
        "        Calculates the SARI score (Summarization Accuracy with Respect to ROUGE) for the validation batch.\n",
        "\n",
        "        Args:\n",
        "            batch (dict): Batch of validation data.\n",
        "\n",
        "        Returns:\n",
        "            float: SARI score for the batch.\n",
        "        \"\"\"\n",
        "\n",
        "        def generate(sentence):\n",
        "            encoding = self.tokenizer(\n",
        "                [sentence],\n",
        "                max_length=self.max_seq_length,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                return_tensors='pt'\n",
        "            ).to(self.device)\n",
        "\n",
        "            input_ids = encoding['input_ids']\n",
        "            attention_mask = encoding['attention_mask']\n",
        "\n",
        "            beam_outputs = self.model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                do_sample=True,\n",
        "                max_length=256,\n",
        "                num_beams=5,\n",
        "                top_k=120,\n",
        "                top_p=0.95,\n",
        "                early_stopping=True,\n",
        "                num_return_sequences=1\n",
        "            ).to(self.device)\n",
        "\n",
        "            return self.tokenizer.decode(beam_outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "        pred_sents = [generate(source) for source in batch[\"source\"]]\n",
        "        score = corpus_sari(batch[\"source\"], pred_sents, [batch[\"targets\"]])\n",
        "        loss = 1 - score / 100\n",
        "        save_log(\n",
        "            self.training_parameters['output_dir'],\n",
        "            self.training_parameters['model_name'],\n",
        "            self.current_epoch,\n",
        "            loss=loss,\n",
        "            sari=score,\n",
        "            data_type='validation'\n",
        "        )\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"\n",
        "        Configures the optimizer and learning rate scheduler.\n",
        "\n",
        "        Returns:\n",
        "            list: A list containing the optimizer and scheduler.\n",
        "        \"\"\"\n",
        "        model = self.model\n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\n",
        "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": self.weight_decay,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "            },\n",
        "        ]\n",
        "\n",
        "        optimizer = AdamW(optimizer_grouped_parameters, lr=self.learning_rate, eps=self.adam_epsilon)\n",
        "\n",
        "        # Calculate the total training steps\n",
        "        t_total = (\n",
        "                (\n",
        "                        len(self.train_dataloader().dataset) // self.train_batch_size\n",
        "                ) // self.gradient_accumulation_steps\n",
        "                * float(self.num_train_epochs)\n",
        "        )\n",
        "\n",
        "        if self.scheduler_type == 'cosine':\n",
        "            scheduler = get_cosine_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=self.warmup_steps, num_training_steps=t_total\n",
        "            )\n",
        "        else:\n",
        "            scheduler = get_linear_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=self.warmup_steps, num_training_steps=t_total\n",
        "            )\n",
        "\n",
        "        return [optimizer], [{'scheduler': scheduler, 'interval': 'step', 'frequency': 1}]\n",
        "\n",
        "    def save_core_model(self):\n",
        "        \"\"\"\n",
        "        Saves the fine-tuned model and tokenizer to the specified directory.\n",
        "        \"\"\"\n",
        "        self.model.save_pretrained(self.model_store_path)\n",
        "        self.tokenizer.save_pretrained(self.model_store_path)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        \"\"\"\n",
        "        Returns the training DataLoader.\n",
        "\n",
        "        Returns:\n",
        "            DataLoader: The training DataLoader.\n",
        "        \"\"\"\n",
        "        train_dataset = TrainDataset(\n",
        "            data_set_dir=self.data_location,\n",
        "            dataset=self.dataset,\n",
        "            tokenizer=self.tokenizer,\n",
        "            max_len=self.max_seq_length,\n",
        "            sample_size=self.train_sample_size,\n",
        "        )\n",
        "        dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=self.train_batch_size,\n",
        "            drop_last=True,\n",
        "            shuffle=True,\n",
        "            pin_memory=True,\n",
        "            num_workers=0\n",
        "        )\n",
        "        return dataloader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        \"\"\"\n",
        "        Returns the validation DataLoader.\n",
        "\n",
        "        Returns:\n",
        "            DataLoader: The validation DataLoader.\n",
        "        \"\"\"\n",
        "        val_dataset = ValDataset(\n",
        "            data_set_dir=self.data_location,\n",
        "            dataset=self.dataset,\n",
        "            tokenizer=self.tokenizer,\n",
        "            max_len=self.max_seq_length,\n",
        "            sample_size=self.valid_sample_size\n",
        "        )\n",
        "        return DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=self.valid_batch_size\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9a169cec-6363-4943-923b-8c0698c07c8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a169cec-6363-4943-923b-8c0698c07c8f",
        "outputId": "a01088b7-589f-43d6-c1a6-e7f96b3c9f30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# from keyword_prompting\n",
        "\n",
        "from keybert import KeyBERT\n",
        "\n",
        "# Initialize KeyBERT model\n",
        "keybert_model = KeyBERT()\n",
        "\n",
        "\n",
        "# Function to extract keywords with KeyBERT\n",
        "def extract_keywords(text, top_n=5, diversity=0.5):\n",
        "    \"\"\"\n",
        "    Extracts keywords from a text using KeyBERT.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text.\n",
        "        top_n (int): Number of top keywords to extract.\n",
        "        diversity (float): Controls the diversity of keywords (0 = low diversity, 1 = high diversity).\n",
        "\n",
        "    Returns:\n",
        "        list: List of tuples containing keywords and their scores.\n",
        "    \"\"\"\n",
        "    return keybert_model.extract_keywords(text, top_n=top_n, diversity=diversity)\n",
        "\n",
        "\n",
        "# Function to create prompts using the kw_score strategy\n",
        "def create_kw_score_prompt(text, top_n=5, diversity=0.5):\n",
        "    \"\"\"\n",
        "    Creates a prompt using the kw_score strategy.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text.\n",
        "        top_n (int): Number of keywords to extract.\n",
        "        diversity (float): Controls the diversity of keywords (0 = low diversity, 1 = high diversity).\n",
        "\n",
        "    Returns:\n",
        "        str: The generated prompt.\n",
        "    \"\"\"\n",
        "    keywords = extract_keywords(text, top_n, diversity)\n",
        "    keyword_prompt = \" \".join([f\"{kw[0]}:{kw[1]:.2f}\" for kw in keywords])\n",
        "    return f\"{keyword_prompt} {text}\"\n",
        "\n",
        "\n",
        "# Function to create prompts using the kw_sep strategy\n",
        "def create_kw_sep_prompt(text, top_n=5, diversity=0.5):\n",
        "    \"\"\"\n",
        "    Creates a prompt using the kw_sep strategy.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text.\n",
        "        top_n (int): Number of keywords to extract.\n",
        "        diversity (float): Controls the diversity of keywords (0 = low diversity, 1 = high diversity).\n",
        "\n",
        "    Returns:\n",
        "        str: The generated prompt.\n",
        "    \"\"\"\n",
        "    keywords = extract_keywords(text, top_n, diversity)\n",
        "    keyword_prompt = \" </s> \".join([kw[0] for kw in keywords]) + \" </s>\"\n",
        "    return f\"{keyword_prompt} {text}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "86708373-8ff2-4ccd-805b-e9f36b4d79df",
      "metadata": {
        "id": "86708373-8ff2-4ccd-805b-e9f36b4d79df"
      },
      "outputs": [],
      "source": [
        "# from evaluate_model.simsum_evaluator\n",
        "\n",
        "# Import necessary libraries\n",
        "from nltk.tokenize import word_tokenize\n",
        "from pathlib import Path\n",
        "import textstat\n",
        "# from util.processing.preprocessor import get_data_filepath\n",
        "# from util.simsum_models.keyword_prompting import create_kw_sep_prompt, create_kw_score_prompt\n",
        "from easse.sari import corpus_sari as easse_corpus_sari\n",
        "from easse.fkgl import corpus_fkgl as easse_corpus_fkgl\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def load_dataset(dataset_dir, dataset_name, phase='test'):\n",
        "    \"\"\"\n",
        "    Load the dataset for evaluation.\n",
        "\n",
        "    Args:\n",
        "        dataset_dir (str or Path): Path to the dataset directory.\n",
        "        dataset_name (str): Name of the dataset (e.g., 'dwiki' or 'wiki_doc').\n",
        "        phase (str): Dataset phase to load ('train', 'valid', 'test').\n",
        "\n",
        "    Returns:\n",
        "        tuple: (list of complex sentences, list of simple sentences)\n",
        "    \"\"\"\n",
        "    complex_filepath = get_data_filepath(dataset_dir, dataset_name, phase, 'complex')\n",
        "    simple_filepath = get_data_filepath(dataset_dir, dataset_name, phase, 'simple')\n",
        "\n",
        "    # Read lines from files\n",
        "    complex_sents = Path(complex_filepath).read_text().splitlines()\n",
        "    simple_sents = Path(simple_filepath).read_text().splitlines()\n",
        "\n",
        "    return complex_sents, simple_sents\n",
        "\n",
        "\n",
        "class SumSimEvaluator:\n",
        "    \"\"\"\n",
        "    A class for evaluating a SumSim-based summarization model using SARI, D-SARI, and FKGL metrics.\n",
        "\n",
        "    Args:\n",
        "        model_config : Configuration dictionary containing the device to run the model on (\"cuda\", \"cpu\", or \"cpu\").\n",
        "        summarizer (AutoModelForSeq2SeqLM): Pre-trained summarization model.\n",
        "        simplifier (AutoModelForSeq2SeqLM): Pre-trained simplification model.\n",
        "        summarizer_tokenizer (AutoTokenizer): Tokenizer for the summarization model.\n",
        "        simplifier_tokenizer (AutoTokenizer): Tokenizer for the simplification model.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_config, summarizer, simplifier, summarizer_tokenizer, simplifier_tokenizer):\n",
        "        self.summarizer = summarizer.to(model_config['device'])\n",
        "        self.simplifier = simplifier.to(model_config['device'])\n",
        "        self.summarizer_tokenizer = summarizer_tokenizer\n",
        "        self.simplifier_tokenizer = simplifier_tokenizer\n",
        "        self.device = model_config['device']\n",
        "        self.max_seq_length = model_config['max_seq_length']\n",
        "        self.prompting_strategy = model_config.get('prompting_strategy', 'kw_sep')\n",
        "        self.output_location = model_config['output_dir']\n",
        "\n",
        "    def generate_summary(self, sentence, max_length=256):\n",
        "        \"\"\"\n",
        "        Generate a summary for a given input sentence using the summarizer.\n",
        "\n",
        "        Args:\n",
        "            sentence (str): Input sentence to be summarized.\n",
        "            max_length (int): Maximum length of the generated summary.\n",
        "\n",
        "        Returns:\n",
        "            str: Generated summary.\n",
        "        \"\"\"\n",
        "        inputs = self.summarizer_tokenizer(\n",
        "            sentence,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=self.max_seq_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\"\n",
        "        ).to(self.device)\n",
        "\n",
        "        input_ids = inputs[\"input_ids\"]\n",
        "        attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "        summary_ids = self.summarizer.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=max_length,\n",
        "            num_beams=5,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "        return self.summarizer_tokenizer.decode(summary_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "    def generate_simplified_text(self, source_sent):\n",
        "        \"\"\"\n",
        "        Generate simplified text using the SumSim model with keyword prompting.\n",
        "\n",
        "        Args:\n",
        "            source_sent (str): Source sentence to be simplified.\n",
        "\n",
        "        Returns:\n",
        "            str: Simplified text.\n",
        "        \"\"\"\n",
        "        # Apply keyword prompting based on strategy\n",
        "        if self.prompting_strategy == 'kw_score':\n",
        "            prompt_text = create_kw_score_prompt(source_sent)\n",
        "        elif self.prompting_strategy == 'kw_sep':\n",
        "            prompt_text = create_kw_sep_prompt(source_sent)\n",
        "        else:\n",
        "            prompt_text = source_sent\n",
        "\n",
        "        # Generate summary using the summarizer\n",
        "        summary = self.generate_summary(prompt_text)\n",
        "\n",
        "        # Tokenize the summary for simplification\n",
        "        inputs = self.simplifier_tokenizer(\n",
        "            summary,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=self.max_seq_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\"\n",
        "        ).to(self.device)\n",
        "\n",
        "        input_ids = inputs[\"input_ids\"]\n",
        "        attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "        # Generate simplified output using the simplifier\n",
        "        simplified_ids = self.simplifier.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=256,\n",
        "            num_beams=5,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "        return self.simplifier_tokenizer.decode(simplified_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_sari_and_d_sari(source_sent, predicted_sent, references):\n",
        "        \"\"\"\n",
        "        Calculate SARI and D-SARI scores for text simplification.\n",
        "\n",
        "        Args:\n",
        "            source_sent (str): Source sentence.\n",
        "            predicted_sent (str): Predicted simplified sentence.\n",
        "            references (list): List of reference simplified sentences.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (SARI score, D-SARI score)\n",
        "        \"\"\"\n",
        "        source_tokens = set(word_tokenize(source_sent))\n",
        "        predicted_tokens = set(word_tokenize(predicted_sent))\n",
        "        reference_tokens = [set(word_tokenize(ref)) for ref in references]\n",
        "\n",
        "        # Calculate addition, deletion, and keep scores\n",
        "        add_scores = [\n",
        "            len(predicted_tokens - ref) / max(1, len(predicted_tokens))\n",
        "            for ref in reference_tokens\n",
        "        ]\n",
        "        keep_scores = [\n",
        "            len(predicted_tokens & ref) / max(1, len(ref))\n",
        "            for ref in reference_tokens\n",
        "        ]\n",
        "        delete_score = len(source_tokens - predicted_tokens) / max(1, len(source_tokens))\n",
        "\n",
        "        sari = (sum(add_scores) + sum(keep_scores) + delete_score) / (len(add_scores) + len(keep_scores) + 1)\n",
        "        d_sari = delete_score  # D-SARI focuses specifically on the deletion component\n",
        "\n",
        "        return sari, d_sari\n",
        "\n",
        "    def calculate_fkgl(self, text):\n",
        "        \"\"\"\n",
        "        Calculate the Flesch-Kincaid Grade Level (FKGL) score.\n",
        "\n",
        "        Args:\n",
        "            text (str): Input text.\n",
        "\n",
        "        Returns:\n",
        "            float: FKGL score.\n",
        "        \"\"\"\n",
        "        return textstat.flesch_kincaid_grade(text)\n",
        "\n",
        "    import pandas as pd\n",
        "\n",
        "    def evaluate(self, source_sentences, reference_sentences):\n",
        "        \"\"\"\n",
        "        Evaluate a set of source and reference sentences using SARI, D-SARI, and FKGL metrics.\n",
        "\n",
        "        Args:\n",
        "            source_sentences (list): List of source sentences to be simplified.\n",
        "            reference_sentences (list): List of corresponding reference sentences.\n",
        "\n",
        "        Returns:\n",
        "            dict: Dictionary containing average SARI, D-SARI, and FKGL scores.\n",
        "        \"\"\"\n",
        "        total_sari, total_d_sari, total_fkgl = 0, 0, 0\n",
        "        predictions = []\n",
        "        metrics = []\n",
        "\n",
        "        for i, source_sent in enumerate(tqdm(source_sentences, desc=\"Evaluating sentences\")):\n",
        "            try:\n",
        "                predicted_sent = self.generate_simplified_text(source_sent)\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating simplified text for sample {i}: {e}\")\n",
        "                predicted_sent = \"\"  # Fallback to an empty prediction\n",
        "\n",
        "            predictions.append(predicted_sent)\n",
        "            references = [reference_sentences[i]]  # Assuming one reference per source\n",
        "\n",
        "            # Calculate SARI and D-SARI scores\n",
        "            sari, d_sari = self.calculate_sari_and_d_sari(source_sent, predicted_sent, references)\n",
        "            total_sari += sari\n",
        "            total_d_sari += d_sari\n",
        "\n",
        "            # Calculate FKGL score\n",
        "            fkgl = self.calculate_fkgl(predicted_sent)\n",
        "            total_fkgl += fkgl\n",
        "\n",
        "            # Calculate EASSE SARI and FKGL for this sample\n",
        "            try:\n",
        "                easse_sari = easse_corpus_sari(orig_sents=[source_sent], sys_sents=[predicted_sent],\n",
        "                                               refs_sents=[references])\n",
        "                easse_fkgl = easse_corpus_fkgl([predicted_sent])\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculating EASSE metrics for sample {i}: {e}\")\n",
        "                easse_sari = 0\n",
        "                easse_fkgl = 0\n",
        "\n",
        "            # # Print metrics for the sample\n",
        "            # print(f\"Sample {i + 1}/{len(source_sentences)}\")\n",
        "            # print(f\"Source: {source_sent}\")\n",
        "            # print(f\"Predicted: {predicted_sent}\")\n",
        "            # print(f\"Reference: {references[0]}\")\n",
        "            # print(f\"SARI: {sari:.2f}, D-SARI: {d_sari:.2f}, FKGL: {fkgl:.2f}\")\n",
        "            # print(f\"EASSE SARI: {easse_sari:.2f}, EASSE FKGL: {easse_fkgl:.2f}\\n\")\n",
        "\n",
        "            # Store metrics in a dictionary\n",
        "            metrics.append({\n",
        "                'Sample': i + 1,\n",
        "                'Source': source_sent,\n",
        "                'Predicted': predicted_sent,\n",
        "                'Reference': references[0],\n",
        "                'SARI': sari,\n",
        "                'D-SARI': d_sari,\n",
        "                'FKGL': fkgl,\n",
        "                'EASSE SARI': easse_sari,\n",
        "                'EASSE FKGL': easse_fkgl\n",
        "            })\n",
        "\n",
        "        # Calculate average scores\n",
        "        avg_sari = total_sari / len(source_sentences)\n",
        "        avg_d_sari = total_d_sari / len(source_sentences)\n",
        "        avg_fkgl = total_fkgl / len(source_sentences)\n",
        "\n",
        "        # Calculate EASSE SARI and FKGL scores for all predictions\n",
        "        try:\n",
        "            easse_sari = easse_corpus_sari(orig_sents=source_sentences, sys_sents=predictions,\n",
        "                                           refs_sents=[reference_sentences])\n",
        "            easse_fkgl = easse_corpus_fkgl(predictions)\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating EASSE metrics for all predictions: {e}\")\n",
        "            easse_sari = 0\n",
        "            easse_fkgl = 0\n",
        "\n",
        "        print(f\"Average SARI: {avg_sari:.2f}\")\n",
        "        print(f\"Average D-SARI: {avg_d_sari:.2f}\")\n",
        "        print(f\"Average FKGL: {avg_fkgl:.2f}\")\n",
        "        print(f\"EASSE SARI: {easse_sari:.2f}\")\n",
        "        print(f\"EASSE FKGL: {easse_fkgl:.2f}\")\n",
        "\n",
        "        # Save metrics to a CSV file using pandas\n",
        "        df = pd.DataFrame(metrics)\n",
        "        df.to_csv('{}/evaluation_metrics_simsum.csv'.format(self.output_location), index=False)\n",
        "\n",
        "        return {\n",
        "            \"SARI\": avg_sari,\n",
        "            \"D-SARI\": avg_d_sari,\n",
        "            \"FKGL\": avg_fkgl,\n",
        "            \"EASSE SARI\": easse_sari,\n",
        "            \"EASSE FKGL\": easse_fkgl\n",
        "        }, df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3123bfc3-4b9b-4f10-8a4e-72697493fa1b",
      "metadata": {
        "id": "3123bfc3-4b9b-4f10-8a4e-72697493fa1b"
      },
      "outputs": [],
      "source": [
        "# functions from utils.train\n",
        "# Import relevant libraries\n",
        "import os\n",
        "import logging\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "# from util.baseline_models.baseline_model import Seq2SeqFineTunedModel\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class LoggingCallback(pl.Callback):\n",
        "    def on_validation_end(self, trainer, pl_module):\n",
        "        \"\"\"\n",
        "        Logs validation results at the end of each validation epoch.\n",
        "        \"\"\"\n",
        "        logger.info(\"***** Validation results *****\")\n",
        "        if hasattr(pl_module, \"is_logger\") and pl_module.is_logger():\n",
        "            metrics = trainer.callback_metrics\n",
        "            for key in sorted(metrics):\n",
        "                if key not in [\"log\", \"progress_bar\"]:\n",
        "                    logger.info(f\"{key} = {metrics[key]}\\n\")\n",
        "                    print(f\"{key}: {metrics[key]}\")\n",
        "\n",
        "    def on_test_end(self, trainer, pl_module):\n",
        "        \"\"\"\n",
        "        Logs and saves test results to a file at the end of testing.\n",
        "        \"\"\"\n",
        "        logger.info(\"***** Test results *****\")\n",
        "        if hasattr(pl_module, \"is_logger\") and pl_module.is_logger():\n",
        "            metrics = trainer.callback_metrics\n",
        "            output_file = os.path.join(pl_module.args.output_dir, \"test_results.txt\")\n",
        "            with open(output_file, \"w\") as writer:\n",
        "                for key in sorted(metrics):\n",
        "                    if key not in [\"log\", \"progress_bar\"]:\n",
        "                        logger.info(f\"{key} = {metrics[key]}\\n\")\n",
        "                        writer.write(f\"{key} = {metrics[key]}\\n\")\n",
        "\n",
        "\n",
        "def train(model_config, model_instance=None):\n",
        "    \"\"\"\n",
        "    Function to train the model.\n",
        "\n",
        "    Args:\n",
        "        model_config: Dictionary containing model configurations.\n",
        "        model_instance: Instance of the model to be trained (optional).\n",
        "    \"\"\"\n",
        "    # Seed for reproducibility\n",
        "    seed = model_config.get('seed', 42)\n",
        "    pl.seed_everything(seed)\n",
        "\n",
        "    # Model checkpointing configuration\n",
        "    model_name = model_config.get('model_name')\n",
        "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "        dirpath=model_config['output_dir'],\n",
        "        filename=f\"{model_name}-checkpoint-{{epoch}}\",\n",
        "        monitor=\"val_loss\",\n",
        "        verbose=True,\n",
        "        mode=\"min\",\n",
        "        save_top_k=1\n",
        "    )\n",
        "    # Progress bar callback\n",
        "    bar_callback = pl.callbacks.TQDMProgressBar(refresh_rate=1)\n",
        "\n",
        "    # Training parameters\n",
        "    train_params = {\n",
        "        'accumulate_grad_batches': model_config.get('gradient_accumulation_steps', 1),\n",
        "        'max_epochs': model_config.get('num_train_epochs', 5),\n",
        "        'callbacks': [LoggingCallback(), checkpoint_callback, bar_callback],\n",
        "        'logger': TensorBoardLogger(f\"{model_config['output_dir']}/logs\"),\n",
        "        'num_sanity_val_steps': 0\n",
        "    }\n",
        "\n",
        "    # Model initialization (if model instance is not provided)\n",
        "    if model_instance is None:\n",
        "        print(\"Initializing baseline model...\")\n",
        "        model = Seq2SeqFineTunedModel(model_config)\n",
        "    else:\n",
        "        model = model_instance\n",
        "\n",
        "    # Trainer setup and training\n",
        "    trainer = pl.Trainer(**train_params)\n",
        "    print(\"Starting training...\")\n",
        "    trainer.fit(model)\n",
        "    print(\"Training finished.\")\n",
        "\n",
        "    # Saving the trained model\n",
        "    output_dir = model_config['output_dir']\n",
        "    if \"simsum\" in model_name:\n",
        "        summarizer_save_path = os.path.join(output_dir, f\"{model_name}-summarizer-final\")\n",
        "        simplifier_save_path = os.path.join(output_dir, f\"{model_name}-simplifier-final\")\n",
        "        print(f\"Saving summarizer to {summarizer_save_path}...\")\n",
        "        model.summarizer.save_pretrained(summarizer_save_path)\n",
        "        model.summarizer_tokenizer.save_pretrained(summarizer_save_path)\n",
        "        print(f\"Summarizer saved at {summarizer_save_path}.\")\n",
        "\n",
        "        print(f\"Saving simplifier to {simplifier_save_path}...\")\n",
        "        model.simplifier.save_pretrained(simplifier_save_path)\n",
        "        model.simplifier_tokenizer.save_pretrained(simplifier_save_path)\n",
        "        print(f\"Simplifier saved at {simplifier_save_path}.\")\n",
        "    else:\n",
        "        model_save_path = os.path.join(output_dir, f\"{model_name}-final\")\n",
        "        print(f\"Saving model to {model_save_path}...\")\n",
        "        model.model.save_pretrained(model_save_path)\n",
        "        model.tokenizer.save_pretrained(model_save_path)\n",
        "        print(f\"Model saved at {model_save_path}.\")\n",
        "\n",
        "    return model, output_dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "04517f33-c3dc-45e9-81fd-43a4ed3763df",
      "metadata": {
        "id": "04517f33-c3dc-45e9-81fd-43a4ed3763df"
      },
      "outputs": [],
      "source": [
        "# from generate_plots\n",
        "\n",
        "# Import relevant libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "\n",
        "def identify_files(folder_path):\n",
        "    \"\"\"\n",
        "    Identifies and categorizes files in a specified folder based on\n",
        "    substrings \"_training_log\", \"_validation_log\", and \"_evaluation_metrics\".\n",
        "\n",
        "    Parameters:\n",
        "    - folder_path (str): Path to the folder containing files.\n",
        "\n",
        "    Returns:\n",
        "    - dict: A dictionary with categorized files, with keys:\n",
        "      'training_log', 'validation_log', and 'evaluation_metrics'.\n",
        "    \"\"\"\n",
        "    categorized_files = {\n",
        "        'training_log': None,\n",
        "        'validation_log': None,\n",
        "        'evaluation_metrics': None\n",
        "    }\n",
        "\n",
        "    # Iterate over files in the folder\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if \"_training_log\" in file_name:\n",
        "            categorized_files['training_log'] = os.path.join(folder_path, file_name)\n",
        "        elif \"_validation_log\" in file_name:\n",
        "            categorized_files['validation_log'] = os.path.join(folder_path, file_name)\n",
        "        elif \"evaluation_metrics\" in file_name:\n",
        "            categorized_files['evaluation_metrics'] = os.path.join(folder_path, file_name)\n",
        "\n",
        "    return categorized_files\n",
        "\n",
        "\n",
        "def plot_average_loss(output_dir, training_log_path, validation_log_path, output_file='average_loss.csv'):\n",
        "    \"\"\"\n",
        "    Plots the average training and validation loss over epochs, and saves\n",
        "    the averaged loss data to a CSV file.\n",
        "\n",
        "    Parameters:\n",
        "    - output_dir: Output directory\n",
        "    - training_log_path (str): Path to the training log CSV file.\n",
        "    - validation_log_path (str): Path to the validation log CSV file.\n",
        "    - output_file (str): Path to save the output CSV file containing average loss data.\n",
        "    \"\"\"\n",
        "    # Load data\n",
        "    training_log = pd.read_csv(training_log_path)\n",
        "    validation_log = pd.read_csv(validation_log_path)\n",
        "\n",
        "    # Calculate average loss\n",
        "    avg_training_loss = training_log.groupby('epoch')['loss'].mean().reset_index()\n",
        "    avg_training_loss['data_type'] = 'training'\n",
        "    avg_validation_loss = validation_log.groupby('epoch')['loss'].mean().reset_index()\n",
        "    avg_validation_loss['data_type'] = 'validation'\n",
        "\n",
        "    # Combine the data\n",
        "    combined_loss = pd.concat([avg_training_loss, avg_validation_loss], axis=0)\n",
        "    combined_loss.columns = ['epoch', 'average_loss', 'data_type']\n",
        "\n",
        "    # Save to CSV\n",
        "    combined_loss.to_csv(\"{}/{}\".format(output_dir, output_file), index=False)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(avg_training_loss['epoch'], avg_training_loss['loss'], marker='o', linestyle='-', color='b', label='Average Training Loss')\n",
        "    # plt.plot(avg_validation_loss['epoch'], avg_validation_loss['loss'], marker='x', linestyle='--', color='r', label='Average Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Average Loss')\n",
        "    plt.title('Epoch vs Average Training Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(\"{}/loss.png\".format(output_dir))\n",
        "\n",
        "\n",
        "def plot_metric_distributions(output_dir, evaluation_metrics_path, output_file='average_metrics.csv'):\n",
        "    \"\"\"\n",
        "    Plots the distribution of specified metrics from the evaluation metrics data\n",
        "    and saves the averaged metrics to a CSV file.\n",
        "\n",
        "    Parameters:\n",
        "    - output_dir: Output directory\n",
        "    - evaluation_metrics_path (str): Path to the evaluation metrics CSV file.\n",
        "    - output_file (str): Path to save the output CSV file containing average metrics data.\n",
        "    \"\"\"\n",
        "    # Load data\n",
        "    evaluation_metrics = pd.read_csv(evaluation_metrics_path)\n",
        "    metrics_columns = ['SARI', 'D-SARI', 'FKGL', 'EASSE SARI', 'EASSE FKGL']\n",
        "\n",
        "    # Calculate average metrics\n",
        "    avg_metrics = evaluation_metrics[metrics_columns].mean().reset_index()\n",
        "    avg_metrics.columns = ['metric', 'average_value']\n",
        "    avg_metrics['data_type'] = 'evaluation'\n",
        "\n",
        "    # Save to CSV\n",
        "    avg_metrics.to_csv(\"{}/{}\".format(output_dir, output_file), index=False)\n",
        "\n",
        "    # Plot distributions\n",
        "    for metric in metrics_columns:\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        evaluation_metrics[metric].plot(kind='hist', bins=30, alpha=0.7, color='teal', edgecolor='black')\n",
        "        plt.xlabel(metric)\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.title(f'Distribution of {metric}')\n",
        "        plt.grid(True)\n",
        "        plt.savefig(\"{}/metrics_{}.png\".format(output_dir, metric))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "# Import necessary libraries\n",
        "from torch.utils.data import DataLoader\n",
        "import pytorch_lightning as pl\n",
        "from transformers import (\n",
        "    AdamW, AutoModelForSeq2SeqLM, AutoTokenizer,\n",
        "    get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
        ")\n",
        "from easse.sari import corpus_sari\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SumSimModel(pl.LightningModule):\n",
        "    \"\"\"\n",
        "    A PyTorch Lightning model for fine-tuning summarization and simplification using a sequence-to-sequence model\n",
        "    with keyword prompting and custom loss.\n",
        "\n",
        "    Args:\n",
        "        training_parameters (dict): Dictionary of training parameters.\n",
        "        summarizer_model_name (str): Pre-trained summarization model.\n",
        "        simplifier_model_name (str): Pre-trained simplification model.\n",
        "    \"\"\"\n",
        "    def __init__(self, training_parameters, summarizer_model_name='t5-base', simplifier_model_name='t5-base'):\n",
        "        super(SumSimModel, self).__init__()\n",
        "\n",
        "        # Store hyperparameters and initialize model and tokenizer\n",
        "        self.save_hyperparameters()\n",
        "        self.training_parameters = training_parameters\n",
        "        self.device_name = training_parameters['device']\n",
        "\n",
        "        # Initialize parameters from the training dictionary\n",
        "        self.summarizer_model_name = training_parameters.get('summarizer_model_name', summarizer_model_name)\n",
        "        self.simplifier_model_name = training_parameters.get('simplifier_model_name', simplifier_model_name)\n",
        "        self.train_batch_size = training_parameters['train_batch_size']\n",
        "        self.valid_batch_size = training_parameters['valid_batch_size']\n",
        "        self.learning_rate = training_parameters['learning_rate']\n",
        "        self.max_seq_length = training_parameters['max_seq_length']\n",
        "        self.adam_epsilon = training_parameters['adam_epsilon']\n",
        "        self.weight_decay = training_parameters['weight_decay']\n",
        "        self.warmup_steps = training_parameters['warmup_steps']\n",
        "        self.train_sample_size = training_parameters['train_sample_size']\n",
        "        self.valid_sample_size = training_parameters['valid_sample_size']\n",
        "        self.num_train_epochs = training_parameters['num_train_epochs']\n",
        "        self.gradient_accumulation_steps = training_parameters['gradient_accumulation_steps']\n",
        "        self.custom_loss = training_parameters.get('custom_loss', False)\n",
        "        self.lambda_ = training_parameters.get('lambda_', 1)\n",
        "        self.hidden_size = training_parameters.get('hidden_size', 1)\n",
        "        self.w1 = training_parameters.get('w1', 1)\n",
        "        self.top_keywords = training_parameters['top_keywords']\n",
        "        self.div_score = training_parameters['div_score']\n",
        "        self.prompting_strategy = training_parameters.get('prompting_strategy', 'no_prompting')\n",
        "        with open('{}/{}_training_log.csv'.format(\n",
        "                self.training_parameters['output_dir'],\n",
        "                self.training_parameters['model_name']\n",
        "        ), 'w') as f: f.write('epoch,loss\\n')\n",
        "        with open('{}/{}_validation_log.csv'.format(\n",
        "                self.training_parameters['output_dir'],\n",
        "                self.training_parameters['model_name']\n",
        "        ), 'w') as f: f.write('epoch,loss,sari\\n')\n",
        "\n",
        "        # Initialize summarizer and simplifier\n",
        "        self.summarizer = AutoModelForSeq2SeqLM.from_pretrained(self.summarizer_model_name).to(self.device_name)\n",
        "        self.summarizer_tokenizer = AutoTokenizer.from_pretrained(self.summarizer_model_name)\n",
        "\n",
        "        self.simplifier = AutoModelForSeq2SeqLM.from_pretrained(self.simplifier_model_name).to(self.device_name)\n",
        "        self.simplifier_tokenizer = AutoTokenizer.from_pretrained(self.simplifier_model_name)\n",
        "\n",
        "        # Custom weight matrix for embedding similarity\n",
        "        self.W = torch.randn((768, int(self.hidden_size)), requires_grad=True, device=self.device_name)\n",
        "        self.CosSim = nn.CosineSimilarity(dim=2, eps=1e-6)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Data and output paths\n",
        "        self.dataset = self.training_parameters['dataset']\n",
        "        self.data_location = self.training_parameters['data_location']\n",
        "        self.model_store_path = training_parameters['output_dir'] / (training_parameters['model_name'] + '_fine_tuned')\n",
        "\n",
        "    def is_logger(self):\n",
        "        \"\"\"\n",
        "        Returns True if this is the first rank (for distributed training), False otherwise.\n",
        "        \"\"\"\n",
        "        return self.trainer.global_rank <= 0\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, labels=None):\n",
        "        \"\"\"\n",
        "        Forward pass of the simplifier model.\n",
        "        \"\"\"\n",
        "        return self.simplifier(input_ids=input_ids,\n",
        "                               attention_mask=attention_mask,\n",
        "                               decoder_input_ids=decoder_input_ids,\n",
        "                               decoder_attention_mask=decoder_attention_mask,\n",
        "                               labels=labels)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Performs a training step, computes loss based on summarizer and simplifier stages, and logs the results.\n",
        "\n",
        "        Args:\n",
        "            batch (dict): Batch of training data.\n",
        "            batch_idx (int): Index of the current batch.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Loss value for the current batch.\n",
        "        \"\"\"\n",
        "        source = batch[\"source\"]\n",
        "        labels = batch['target_ids']\n",
        "        targets = batch['target']\n",
        "        labels[labels[:, :] == self.simplifier_tokenizer.pad_token_id] = -100\n",
        "\n",
        "        # Select the keyword prompting strategy based on training parameters\n",
        "        if self.training_parameters.get('prompting_strategy') == 'kw_score':\n",
        "            prompt_source = [create_kw_score_prompt(text, self.top_keywords, self.div_score) for text in source]\n",
        "        elif self.training_parameters.get('prompting_strategy') == 'kw_sep':\n",
        "            prompt_source = [create_kw_sep_prompt(text, self.top_keywords, self.div_score) for text in source]\n",
        "        else:\n",
        "            prompt_source = source\n",
        "\n",
        "        # Tokenize targets for the simplifier\n",
        "        targets_encoding = self.simplifier_tokenizer(\n",
        "            targets,\n",
        "            max_length=256,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        tgt_ids = targets_encoding['input_ids'].to(self.device_name)\n",
        "        tgt_mask = targets_encoding['attention_mask'].to(self.device_name)\n",
        "\n",
        "        # Forward pass through the simplifier\n",
        "        tgt_output = self.simplifier(\n",
        "            input_ids=tgt_ids,\n",
        "            attention_mask=tgt_mask,\n",
        "            labels=labels,\n",
        "            decoder_attention_mask=batch['target_mask']\n",
        "        )\n",
        "        H_sim = tgt_output.encoder_last_hidden_state\n",
        "\n",
        "        # Summarizer stage\n",
        "        inputs = self.summarizer_tokenizer(\n",
        "            prompt_source,\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        src_ids = inputs['input_ids'].to(self.device_name)\n",
        "        src_mask = inputs['attention_mask'].to(self.device_name)\n",
        "\n",
        "        # Forward pass through the summarizer\n",
        "        sum_outputs = self.summarizer(\n",
        "            input_ids=src_ids,\n",
        "            attention_mask=src_mask,\n",
        "            labels=labels,\n",
        "            decoder_attention_mask=batch['target_mask']\n",
        "        )\n",
        "\n",
        "        # Generate summary\n",
        "        summary_ids = self.summarizer.generate(\n",
        "            inputs['input_ids'].to(self.device_name),\n",
        "            do_sample=True,\n",
        "            num_beams=5,\n",
        "            min_length=10,\n",
        "            max_length=256\n",
        "        ).to(self.device_name)\n",
        "\n",
        "        # Pad summaries for simplifier input\n",
        "        padded_summary_ids = torch.zeros((summary_ids.shape[0], 256), dtype=torch.long).fill_(\n",
        "            self.simplifier_tokenizer.pad_token_id).to(self.device_name)\n",
        "        for i, summary_id in enumerate(summary_ids):\n",
        "            padded_summary_ids[i, :summary_id.shape[0]] = summary_id\n",
        "\n",
        "        summary_attention_mask = torch.ones(padded_summary_ids.shape).to(self.device_name)\n",
        "        summary_attention_mask[padded_summary_ids[:, :] == self.simplifier_tokenizer.pad_token_id] = 0\n",
        "\n",
        "        # Forward pass through the simplifier with summaries\n",
        "        sim_outputs = self(\n",
        "            input_ids=padded_summary_ids,\n",
        "            attention_mask=summary_attention_mask,\n",
        "            labels=labels,\n",
        "            decoder_attention_mask=batch['target_mask']\n",
        "        )\n",
        "        H2 = sim_outputs.encoder_last_hidden_state\n",
        "\n",
        "        # Compute similarity\n",
        "        Rep1 = torch.matmul(H_sim, self.W)\n",
        "        Rep2 = torch.matmul(H2, self.W)\n",
        "        Rep1 = self.relu(Rep1)\n",
        "        Rep2 = self.relu(Rep2)\n",
        "        sim_score = self.CosSim(Rep1, Rep2)\n",
        "\n",
        "        # Custom loss logic\n",
        "        if self.training_parameters.get('custom_loss'):\n",
        "            loss = sim_outputs.loss * self.training_parameters['w1']\n",
        "            loss += (-self.training_parameters['lambda_'] * (sim_score.mean(dim=1).mean(dim=0)))\n",
        "            self.log('train_loss', sim_outputs.loss, on_step=True, prog_bar=True, logger=True)\n",
        "        else:\n",
        "            loss = sim_outputs.loss\n",
        "            self.log('train_loss', loss, on_step=True, prog_bar=True, logger=True)\n",
        "\n",
        "        # Save loss for each data point\n",
        "        save_log(\n",
        "            self.training_parameters['output_dir'],\n",
        "            self.training_parameters['model_name'],\n",
        "            self.current_epoch,\n",
        "            loss=loss.item(),\n",
        "            data_type='train'\n",
        "        )\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Performs a validation step, computes and accumulates SARI scores, and logs the results.\n",
        "\n",
        "        Args:\n",
        "            batch (dict): Batch of validation data.\n",
        "            batch_idx (int): Index of the current batch.\n",
        "\n",
        "        Returns:\n",
        "            float: SARI score for the current batch.\n",
        "        \"\"\"\n",
        "        loss = self.sari_validation_step(batch)\n",
        "        self.log('val_loss', loss, batch_size=self.training_parameters['valid_batch_size'])\n",
        "\n",
        "        return torch.tensor(loss, dtype=float)\n",
        "\n",
        "    def sari_validation_step(self, batch):\n",
        "        \"\"\"\n",
        "        Calculates the SARI score (Summarization Accuracy with Respect to ROUGE) for the validation batch.\n",
        "\n",
        "        Args:\n",
        "            batch (dict): Batch of validation data.\n",
        "\n",
        "        Returns:\n",
        "            float: SARI score for the batch.\n",
        "        \"\"\"\n",
        "        def generate(sentence):\n",
        "            inputs = self.summarizer_tokenizer(\n",
        "                [\"summarize: \" + sentence],\n",
        "                max_length=512,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "            summary_ids = self.summarizer.generate(\n",
        "                inputs['input_ids'].to(self.device_name),\n",
        "                num_beams=15,\n",
        "                max_length=256,\n",
        "                top_k=130,\n",
        "                top_p=0.95\n",
        "            ).to(self.device_name)\n",
        "\n",
        "            summary_attention_mask = torch.ones(summary_ids.shape).to(self.device_name)\n",
        "            summary_attention_mask[summary_ids[:, :] == self.summarizer_tokenizer.pad_token_id] = 0\n",
        "\n",
        "            beam_outputs = self.simplifier.generate(\n",
        "                input_ids=summary_ids,\n",
        "                attention_mask=summary_attention_mask,\n",
        "                do_sample=True,\n",
        "                max_length=256,\n",
        "                num_beams=2,\n",
        "                top_k=80,\n",
        "                top_p=0.90,\n",
        "                early_stopping=True,\n",
        "                num_return_sequences=1\n",
        "            ).to(self.device_name)\n",
        "            return self.simplifier_tokenizer.decode(\n",
        "                beam_outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
        "            )\n",
        "\n",
        "        pred_sents = [generate(source) for source in batch[\"source\"]]\n",
        "        score = corpus_sari(batch[\"source\"], pred_sents, [batch[\"targets\"]])\n",
        "        loss = 1 - score / 100\n",
        "        save_log(\n",
        "            self.training_parameters['output_dir'],\n",
        "            self.training_parameters['model_name'],\n",
        "            self.current_epoch,\n",
        "            loss=loss,\n",
        "            sari=score,\n",
        "            data_type='validation'\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"\n",
        "        Configures the optimizer and learning rate scheduler.\n",
        "\n",
        "        Returns:\n",
        "            list: A list containing the optimizer and scheduler.\n",
        "        \"\"\"\n",
        "        model1 = self.summarizer\n",
        "        model2 = self.simplifier\n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\n",
        "                \"params\": [p for n, p in model2.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": self.training_parameters['weight_decay'],\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in model2.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in model1.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": self.training_parameters['weight_decay'],\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in model1.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "            },\n",
        "            {\n",
        "                \"params\": self.W\n",
        "            },\n",
        "        ]\n",
        "        optimizer = AdamW(optimizer_grouped_parameters, lr=self.training_parameters['learning_rate'], eps=self.training_parameters['adam_epsilon'])\n",
        "        t_total = (\n",
        "                (\n",
        "                        len(self.train_dataloader().dataset) // self.training_parameters['train_batch_size']\n",
        "                ) // self.training_parameters['gradient_accumulation_steps']\n",
        "                * float(self.training_parameters['num_train_epochs'])\n",
        "        )\n",
        "\n",
        "        if self.training_parameters['scheduler_type'] == 'cosine':\n",
        "            scheduler = get_cosine_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=self.training_parameters['warmup_steps'], num_training_steps=t_total\n",
        "            )\n",
        "        else:\n",
        "            scheduler = get_linear_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=self.training_parameters['warmup_steps'], num_training_steps=t_total\n",
        "            )\n",
        "\n",
        "        return [optimizer], [{'scheduler': scheduler, 'interval': 'step', 'frequency': 1}]\n",
        "\n",
        "    def save_core_model(self):\n",
        "        \"\"\"\n",
        "        Saves the fine-tuned model and tokenizer to the specified directory.\n",
        "        \"\"\"\n",
        "        self.model.save_pretrained(self.model_store_path)\n",
        "        self.tokenizer.save_pretrained(self.model_store_path)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        \"\"\"\n",
        "        Returns the training DataLoader.\n",
        "\n",
        "        Returns:\n",
        "            DataLoader: The training DataLoader.\n",
        "        \"\"\"\n",
        "        train_dataset = TrainDataset(\n",
        "            data_set_dir=self.data_location,\n",
        "            dataset=self.dataset,\n",
        "            tokenizer=self.simplifier_tokenizer,\n",
        "            max_len=self.max_seq_length,\n",
        "            sample_size=self.train_sample_size,\n",
        "        )\n",
        "        dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=self.train_batch_size,\n",
        "            drop_last=True,\n",
        "            shuffle=True,\n",
        "            pin_memory=True,\n",
        "            num_workers=0\n",
        "        )\n",
        "        return dataloader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        \"\"\"\n",
        "        Returns the validation DataLoader.\n",
        "\n",
        "        Returns:\n",
        "            DataLoader: The validation DataLoader.\n",
        "        \"\"\"\n",
        "        val_dataset = ValDataset(\n",
        "            data_set_dir=self.data_location,\n",
        "            dataset=self.dataset,\n",
        "            tokenizer=self.simplifier_tokenizer,\n",
        "            max_len=self.max_seq_length,\n",
        "            sample_size=self.valid_sample_size\n",
        "        )\n",
        "        return DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=self.valid_batch_size\n",
        "        )\n"
      ],
      "metadata": {
        "id": "ulajzh_PKjTO"
      },
      "id": "ulajzh_PKjTO",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "38b2c721-76b6-49a5-b851-502167e831d4",
      "metadata": {
        "id": "38b2c721-76b6-49a5-b851-502167e831d4"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "# Import user-defined libraries\n",
        "# from util.utils import create_experiment_dir, log_parameters\n",
        "# from util.train import train\n",
        "# from util.evaluate_model.simsum_evaluator import SumSimEvaluator\n",
        "# from util.evaluate_model.evaluation_metrics import BartModelEvaluator, load_dataset\n",
        "# from util.simsum_models.simsum_model import SumSimModel\n",
        "# from util.baseline_models.baseline_model import Seq2SeqFineTunedModel\n",
        "# from util.generate_plots import plot_average_loss, plot_metric_distributions, identify_files\n",
        "\n",
        "\n",
        "class ModelRunner:\n",
        "    def __init__(self, configuration):\n",
        "        \"\"\"\n",
        "        Initialize the trainer with model configuration.\n",
        "\n",
        "        Args:\n",
        "            configuration: The dictionary containing model configurations\n",
        "        \"\"\"\n",
        "        # Ensure the project root is added to the Python path\n",
        "        # sys.path.append(str(Path(__file__).resolve().parent))\n",
        "\n",
        "        # Initialise the output directory\n",
        "        self.repo_dir = datasets_base_dir\n",
        "        self.exp_dir = os.path.join(self.repo_dir,'outputs')\n",
        "        if not os.path.exists(self.exp_dir):\n",
        "            os.makedirs(self.exp_dir)\n",
        "\n",
        "        # Define the model name\n",
        "        self.model_config = configuration.copy()\n",
        "\n",
        "        # Store the model locations\n",
        "        self.model_config['output_dir'] = create_experiment_dir(self.exp_dir, self.model_config)\n",
        "        self.model_config['data_location'] = os.path.join(self.repo_dir,'datasets')\n",
        "        self.model_config['device'] = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.model_name = configuration['model_name'].lower()\n",
        "        self.model_save_path = None\n",
        "        self.model = None\n",
        "        self.model_details = None\n",
        "        self.select_model()\n",
        "\n",
        "    def select_model(self):\n",
        "        \"\"\"\n",
        "        Function to select the model class and configure the settings based on the model name.\n",
        "        \"\"\"\n",
        "        if self.model_name == 'bart-baseline':\n",
        "            self.model_config['model_name'] = 'facebook/bart-base' # 'Yale-LILY/brio-cnndm-uncased'\n",
        "            self.model_config['scheduler_type'] = 'linear'\n",
        "        elif self.model_name == 't5-baseline':\n",
        "            self.model_config['model_name'] = 't5-base'\n",
        "            self.model_config['scheduler_type'] = 'cosine'\n",
        "        elif self.model_name == 'bart-simsum':\n",
        "            self.model_config['summarizer_model_name'] = 'ainize/bart-base-cnn'\n",
        "            self.model_config['simplifier_model_name'] = 'facebook/bart-base'\n",
        "            self.model_config['scheduler_type'] = 'cosine'\n",
        "            self.model = SumSimModel(\n",
        "                self.model_config,\n",
        "                summarizer_model_name=self.model_config['summarizer_model_name'],\n",
        "                simplifier_model_name=self.model_config['simplifier_model_name']\n",
        "            )\n",
        "        elif self.model_name == 't5-simsum':\n",
        "            self.model_config['summarizer_model_name'] = 't5-base'\n",
        "            self.model_config['simplifier_model_name'] = 't5-base'\n",
        "            self.model_config['scheduler_type'] = 'cosine'\n",
        "            self.model = SumSimModel(\n",
        "                self.model_config,\n",
        "                summarizer_model_name=self.model_config['summarizer_model_name'],\n",
        "                simplifier_model_name=self.model_config['simplifier_model_name']\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(\"Invalid model name. Use 'bart-baseline', 't5-baseline', 'bart-simsum', or 't5-simsum'.\")\n",
        "\n",
        "    def train_model(self):\n",
        "        \"\"\"\n",
        "        Run the training process.\n",
        "        \"\"\"\n",
        "        # Log training arguments\n",
        "        log_parameters(self.model_config['output_dir'] / \"params.json\", self.model_config)\n",
        "\n",
        "        # Start training\n",
        "        print(\n",
        "            f\"Starting training with {self.model_name.upper()} model on dataset: {self.model_config['dataset']}\"\n",
        "        )\n",
        "        if self.model is None:\n",
        "            # Initialize model if not already set (for baseline models)\n",
        "            self.model = Seq2SeqFineTunedModel(self.model_config)\n",
        "        self.model, self.model_save_path = train(self.model_config, self.model)\n",
        "\n",
        "    def evaluate_model(self):\n",
        "        \"\"\"\n",
        "        Function to evaluate the model.\n",
        "        \"\"\"\n",
        "        print(\"Starting evaluation of models\")\n",
        "        if self.model_name in ['bart-simsum', 't5-simsum']:\n",
        "            evaluator = SumSimEvaluator(self.model_config, self.model.summarizer, self.model.simplifier,\n",
        "                                        self.model.summarizer_tokenizer, self.model.simplifier_tokenizer)\n",
        "        else:\n",
        "            # Use standard evaluator for baseline models\n",
        "            evaluator = BartModelEvaluator(self.model_config, self.model.model, self.model.tokenizer)\n",
        "\n",
        "        # Load datasets (D_Wiki and Wiki_Doc)\n",
        "        dataset_dir = self.model_config['data_location']\n",
        "        dataset_name = self.model_config['dataset']\n",
        "\n",
        "        print(f\"Evaluating on {dataset_name}\")\n",
        "        complex_sents, simple_sents = load_dataset_validation(\n",
        "            dataset_dir, dataset_name, percentage=self.model_config['test_sample_size']\n",
        "        )\n",
        "        scores, score_table = evaluator.evaluate(complex_sents, simple_sents)\n",
        "        print(f\"Results for {dataset_name}: {scores}\")\n",
        "\n",
        "        # Generate plots\n",
        "        files = identify_files(self.model_config['output_dir'])\n",
        "        plot_average_loss(self.model_config['output_dir'], files['training_log'], files['validation_log'])\n",
        "        plot_metric_distributions(self.model_config['output_dir'], files['evaluation_metrics'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run code"
      ],
      "metadata": {
        "id": "1zg32R2fHhjV"
      },
      "id": "1zg32R2fHhjV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59aa5933-feeb-463a-8631-fbdbd49dfdf7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590,
          "referenced_widgets": [
            "591722ec78c443cabdc9da815fbccfd0",
            "a9dde734621f4af4b483a06944e49559",
            "5d00d1889d494075acde7584c08c2d5e",
            "278467feb256430da4896979f0bda6f1",
            "81c3b5b6b9c14ee08539e06cade932fe",
            "5bffa9ca35f44af799e19b05e55ccf15",
            "0d00ba9d4bd44b8c9dfa522edafb0848",
            "bf405031830143b997a2cbaf5c4e6a0d",
            "c303e94d0e60402187f7a267fd1c0165",
            "99f96b1010ba482492bbab061efd6ece",
            "8aa0b85172fd4e809719726e6100593f"
          ]
        },
        "id": "59aa5933-feeb-463a-8631-fbdbd49dfdf7",
        "outputId": "00609540-c9a5-4916-fea1-24f4626ff2c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current time: 2024-11-20 04:48:38\n",
            "6_t5-baseline_D_wiki_epochs-10_batch-8_val_batch-8_lambda-0.001_prompt-no_prompting_div-0.5_keywords-5_test_sample-0.1\n",
            "Starting training with T5-BASELINE model on dataset: D_wiki\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 0\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /content/drive/MyDrive/NLP-Sem-3 Project/outputs/6_t5-baseline_D_wiki_epochs-10_batch-8_val_batch-8_lambda-0.001_prompt-no_prompting_div-0.5_keywords-5_test_sample-0.1 exists and is not empty.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Initializing TrainDataset...\n",
            "Dataset paths initialized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                       | Params | Mode\n",
            "------------------------------------------------------------\n",
            "0 | model | T5ForConditionalGeneration | 222 M  | eval\n",
            "------------------------------------------------------------\n",
            "222 M     Trainable params\n",
            "0         Non-trainable params\n",
            "222 M     Total params\n",
            "891.614   Total estimated model params size (MB)\n",
            "0         Modules in train mode\n",
            "541       Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing TrainDataset...\n",
            "Dataset paths initialized.\n",
            "Initializing ValDataset...\n",
            "Dataset paths initialized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "591722ec78c443cabdc9da815fbccfd0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        }
      ],
      "source": [
        "# # Initialise user defined libraries\n",
        "# from model_runner import ModelRunner\n",
        "from datetime import datetime\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "    Run the main functions to summarize text\n",
        "    \"\"\"\n",
        "    # Get the current time\n",
        "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(\"Current time:\", current_time)\n",
        "\n",
        "    configuration = {\n",
        "        'seed': 0,\n",
        "        'gradient_accumulation_steps': 1,\n",
        "        'learning_rate': 1e-5,\n",
        "        'max_seq_length': 256,\n",
        "        'adam_epsilon': 1e-8,\n",
        "        'weight_decay': 0.0001,\n",
        "        'warmup_steps': 5,\n",
        "        'custom_loss': True,\n",
        "        'hidden_size': 1,\n",
        "        'w1': 1,\n",
        "        'num_train_epochs': 10,\n",
        "\n",
        "        # To edit\n",
        "        'model_name': 't5-baseline',\n",
        "        'dataset': 'D_wiki',\n",
        "        'prompting_strategy': 'no_prompting',\n",
        "        'train_batch_size': 8,\n",
        "        'valid_batch_size': 8,\n",
        "        'train_sample_size': 0.02,\n",
        "        'valid_sample_size': 0.02,\n",
        "        'test_sample_size': 0.1,\n",
        "        'lambda_': 0.001,\n",
        "        'div_score': 0.5,\n",
        "        'top_keywords': 5\n",
        "    }\n",
        "\n",
        "    # Initialize, run and evaluate the model\n",
        "    model = ModelRunner(configuration)\n",
        "    model.train_model()\n",
        "    model.evaluate_model()\n",
        "\n",
        "    # Get the current time\n",
        "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(\"Current time:\", current_time)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "591722ec78c443cabdc9da815fbccfd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9dde734621f4af4b483a06944e49559",
              "IPY_MODEL_5d00d1889d494075acde7584c08c2d5e",
              "IPY_MODEL_278467feb256430da4896979f0bda6f1"
            ],
            "layout": "IPY_MODEL_81c3b5b6b9c14ee08539e06cade932fe"
          }
        },
        "a9dde734621f4af4b483a06944e49559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bffa9ca35f44af799e19b05e55ccf15",
            "placeholder": "",
            "style": "IPY_MODEL_0d00ba9d4bd44b8c9dfa522edafb0848",
            "value": "Epoch0:41%"
          }
        },
        "5d00d1889d494075acde7584c08c2d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf405031830143b997a2cbaf5c4e6a0d",
            "max": 242,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c303e94d0e60402187f7a267fd1c0165",
            "value": 100
          }
        },
        "278467feb256430da4896979f0bda6f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99f96b1010ba482492bbab061efd6ece",
            "placeholder": "",
            "style": "IPY_MODEL_8aa0b85172fd4e809719726e6100593f",
            "value": "100/242[01:40&lt;02:22,0.99it/s,v_num=0,train_loss=2.400]"
          }
        },
        "81c3b5b6b9c14ee08539e06cade932fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "5bffa9ca35f44af799e19b05e55ccf15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d00ba9d4bd44b8c9dfa522edafb0848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf405031830143b997a2cbaf5c4e6a0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c303e94d0e60402187f7a267fd1c0165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99f96b1010ba482492bbab061efd6ece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aa0b85172fd4e809719726e6100593f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}